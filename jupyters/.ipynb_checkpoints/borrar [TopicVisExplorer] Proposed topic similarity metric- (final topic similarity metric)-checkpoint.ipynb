{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import gensim, pickle\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "LdaModel = gensim.models.ldamodel.LdaModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ruta_word_embedding = '../data/wiki.multi.en.vec'\n",
    "#ruta_word_embedding = '../data/embedding_english__europe_northamerica_word2vec_300dimensions_cbow_trim3_epoch50.bin'\n",
    "ruta_word_embedding = '../data/embedding_english_europe_northamerica_word2vec_300dimensions_cbow_trim3_epoch50.model'\n",
    "wordembedding = gensim.models.Word2Vec.load(ruta_word_embedding)\n",
    "#wordembedding = KeyedVectors.load_word2vec_format(ruta_word_embedding, binary=False)\n",
    "#wordembedding = KeyedVectors.load_word2vec_format(ruta_word_embedding, binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load topic modelings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Note: \n",
    "LDAvis Scenario:\n",
    "If you wish to calculate topic similarity metric over one topic modeling output, therefore lda_model_collection_1\n",
    "and lda_model_collection_2 should be the same. \n",
    "\n",
    "Sankey diagram scenario:\n",
    "If you wish to calculate topic similarity metric over two different topic modeling outputs, lda_model_collection_1\n",
    "and lda_model_collection_2 should be different\n",
    "\n",
    "\n",
    "The same shouuld be done with the most relevant documents.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "lda_model_collecion_1 = LdaModel.load(\"../data/cambridge_analytica/regional_datasets/files_europe/english_europe_tweets_20190411.csv_gensim.model\")\n",
    "lda_model_collecion_2 = LdaModel.load(\"../data/cambridge_analytica/regional_datasets/files_europe/english_europe_tweets_20190411.csv_gensim.model\")\n",
    "#lda_model_collecion_2 = LdaModel.load(\"../data/cambridge_analytica/regional_datasets/files_northamerica/english_northamerica_tweets_20190411.csv_gensim.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10,\n",
       "  '0.051*\"good\" + 0.037*\"read\" + 0.036*\"make\" + 0.026*\"great\" + 0.021*\"interesting\" + 0.016*\"real\" + 0.016*\"article\" + 0.015*\"happen\" + 0.014*\"lot\" + 0.014*\"point\"'),\n",
       " (9,\n",
       "  '0.043*\"social\" + 0.041*\"medium\" + 0.035*\"news\" + 0.031*\"thing\" + 0.023*\"people\" + 0.020*\"platform\" + 0.019*\"stop\" + 0.019*\"give\" + 0.019*\"internet\" + 0.019*\"bad\"'),\n",
       " (5,\n",
       "  '0.045*\"question\" + 0.034*\"today\" + 0.026*\"watch\" + 0.024*\"time\" + 0.022*\"talk\" + 0.021*\"week\" + 0.020*\"answer\" + 0.018*\"open\" + 0.017*\"hear\" + 0.016*\"day\"'),\n",
       " (6,\n",
       "  '0.131*\"bigdata\" + 0.039*\"late\" + 0.034*\"ai\" + 0.033*\"analytic\" + 0.030*\"machinelearne\" + 0.030*\"technology\" + 0.022*\"marketing\" + 0.020*\"tech\" + 0.020*\"datascience\" + 0.017*\"learn\"'),\n",
       " (0,\n",
       "  '0.055*\"people\" + 0.035*\"delete\" + 0.032*\"year\" + 0.026*\"account\" + 0.022*\"friend\" + 0.021*\"time\" + 0.017*\"back\" + 0.014*\"message\" + 0.014*\"deletefacebook\" + 0.014*\"call\"'),\n",
       " (7,\n",
       "  '0.049*\"facebook\" + 0.047*\"scandal\" + 0.033*\"company\" + 0.032*\"change\" + 0.029*\"make\" + 0.027*\"data\" + 0.016*\"tool\" + 0.016*\"public\" + 0.012*\"world\" + 0.012*\"profile\"'),\n",
       " (1,\n",
       "  '0.035*\"trump\" + 0.033*\"leave\" + 0.025*\"vote\" + 0.023*\"campaign\" + 0.023*\"election\" + 0.019*\"amp\" + 0.017*\"lie\" + 0.015*\"government\" + 0.014*\"democracy\" + 0.013*\"tory\"'),\n",
       " (8,\n",
       "  '0.045*\"work\" + 0.034*\"ad\" + 0.029*\"story\" + 0.019*\"pay\" + 0.017*\"report\" + 0.016*\"target\" + 0.016*\"show\" + 0.014*\"run\" + 0.014*\"party\" + 0.014*\"political\"'),\n",
       " (2,\n",
       "  '0.135*\"datum\" + 0.104*\"privacy\" + 0.074*\"user\" + 0.024*\"personal\" + 0.022*\"information\" + 0.021*\"law\" + 0.019*\"access\" + 0.018*\"app\" + 0.017*\"give\" + 0.015*\"sell\"'),\n",
       " (4,\n",
       "  '0.064*\"facebook\" + 0.034*\"page\" + 0.033*\"follow\" + 0.032*\"find\" + 0.030*\"twitter\" + 0.027*\"post\" + 0.026*\"share\" + 0.024*\"live\" + 0.023*\"check\" + 0.019*\"video\"')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model_collecion_1.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10,\n",
       "  '0.051*\"good\" + 0.037*\"read\" + 0.036*\"make\" + 0.026*\"great\" + 0.021*\"interesting\" + 0.016*\"real\" + 0.016*\"article\" + 0.015*\"happen\" + 0.014*\"lot\" + 0.014*\"point\"'),\n",
       " (9,\n",
       "  '0.043*\"social\" + 0.041*\"medium\" + 0.035*\"news\" + 0.031*\"thing\" + 0.023*\"people\" + 0.020*\"platform\" + 0.019*\"stop\" + 0.019*\"give\" + 0.019*\"internet\" + 0.019*\"bad\"'),\n",
       " (5,\n",
       "  '0.045*\"question\" + 0.034*\"today\" + 0.026*\"watch\" + 0.024*\"time\" + 0.022*\"talk\" + 0.021*\"week\" + 0.020*\"answer\" + 0.018*\"open\" + 0.017*\"hear\" + 0.016*\"day\"'),\n",
       " (6,\n",
       "  '0.131*\"bigdata\" + 0.039*\"late\" + 0.034*\"ai\" + 0.033*\"analytic\" + 0.030*\"machinelearne\" + 0.030*\"technology\" + 0.022*\"marketing\" + 0.020*\"tech\" + 0.020*\"datascience\" + 0.017*\"learn\"'),\n",
       " (0,\n",
       "  '0.055*\"people\" + 0.035*\"delete\" + 0.032*\"year\" + 0.026*\"account\" + 0.022*\"friend\" + 0.021*\"time\" + 0.017*\"back\" + 0.014*\"message\" + 0.014*\"deletefacebook\" + 0.014*\"call\"'),\n",
       " (7,\n",
       "  '0.049*\"facebook\" + 0.047*\"scandal\" + 0.033*\"company\" + 0.032*\"change\" + 0.029*\"make\" + 0.027*\"data\" + 0.016*\"tool\" + 0.016*\"public\" + 0.012*\"world\" + 0.012*\"profile\"'),\n",
       " (1,\n",
       "  '0.035*\"trump\" + 0.033*\"leave\" + 0.025*\"vote\" + 0.023*\"campaign\" + 0.023*\"election\" + 0.019*\"amp\" + 0.017*\"lie\" + 0.015*\"government\" + 0.014*\"democracy\" + 0.013*\"tory\"'),\n",
       " (8,\n",
       "  '0.045*\"work\" + 0.034*\"ad\" + 0.029*\"story\" + 0.019*\"pay\" + 0.017*\"report\" + 0.016*\"target\" + 0.016*\"show\" + 0.014*\"run\" + 0.014*\"party\" + 0.014*\"political\"'),\n",
       " (2,\n",
       "  '0.135*\"datum\" + 0.104*\"privacy\" + 0.074*\"user\" + 0.024*\"personal\" + 0.022*\"information\" + 0.021*\"law\" + 0.019*\"access\" + 0.018*\"app\" + 0.017*\"give\" + 0.015*\"sell\"'),\n",
       " (4,\n",
       "  '0.064*\"facebook\" + 0.034*\"page\" + 0.033*\"follow\" + 0.032*\"find\" + 0.030*\"twitter\" + 0.027*\"post\" + 0.026*\"share\" + 0.024*\"live\" + 0.023*\"check\" + 0.019*\"video\"')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model_collecion_2.show_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load relevant documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/cambridge_analytica/regional_datasets/files_europe/english_europe_tweets_20190411.csvsent_topics_sorteddf_mallet_ldamodel', 'rb') as f:\n",
    "    most_relevant_documents_collection_1 = pickle.load(f)\n",
    "most_relevant_documents_collection_1 = most_relevant_documents_collection_1[['Topic_Num','Topic_Perc_Contrib','text']]\n",
    "\n",
    "# ../data/cambridge_analytica/regional_datasets/files_northamerica/english_northamerica_tweets_20190411.csvsent_topics_sorteddf_mallet_ldamodel\n",
    "with open('../data/cambridge_analytica/regional_datasets/files_europe/english_europe_tweets_20190411.csvsent_topics_sorteddf_mallet_ldamodel', 'rb') as f:\n",
    "    most_relevant_documents_collection_2 = pickle.load(f)\n",
    "most_relevant_documents_collection_2 = most_relevant_documents_collection_2[['Topic_Num','Topic_Perc_Contrib','text']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_Num</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2802</td>\n",
       "      <td>.\\n#NYCACC\\n#DogsOfTwitter\\nROCKY\\n#ATTENTION\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2776</td>\n",
       "      <td>#NYCACC\\n#DogsOfTwitter\\nCAPONE #VID\\n#ATTENTI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2730</td>\n",
       "      <td>&lt;usernameremoved&gt; I can't wait for the followi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2689</td>\n",
       "      <td>.\\n#NYCACC\\n#DogsOfTwitter\\nATLAS #VID\\n#ATTEN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2672</td>\n",
       "      <td>Apparently all my friends are talking about me...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic_Num  Topic_Perc_Contrib  \\\n",
       "0        0.0              0.2802   \n",
       "1        0.0              0.2776   \n",
       "2        0.0              0.2730   \n",
       "3        0.0              0.2689   \n",
       "4        0.0              0.2672   \n",
       "\n",
       "                                                text  \n",
       "0  .\\n#NYCACC\\n#DogsOfTwitter\\nROCKY\\n#ATTENTION\\...  \n",
       "1  #NYCACC\\n#DogsOfTwitter\\nCAPONE #VID\\n#ATTENTI...  \n",
       "2  <usernameremoved> I can't wait for the followi...  \n",
       "3  .\\n#NYCACC\\n#DogsOfTwitter\\nATLAS #VID\\n#ATTEN...  \n",
       "4  Apparently all my friends are talking about me...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_relevant_documents_collection_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1246"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(most_relevant_documents_collection_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_Num</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2802</td>\n",
       "      <td>.\\n#NYCACC\\n#DogsOfTwitter\\nROCKY\\n#ATTENTION\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2776</td>\n",
       "      <td>#NYCACC\\n#DogsOfTwitter\\nCAPONE #VID\\n#ATTENTI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2730</td>\n",
       "      <td>&lt;usernameremoved&gt; I can't wait for the followi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2689</td>\n",
       "      <td>.\\n#NYCACC\\n#DogsOfTwitter\\nATLAS #VID\\n#ATTEN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2672</td>\n",
       "      <td>Apparently all my friends are talking about me...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic_Num  Topic_Perc_Contrib  \\\n",
       "0        0.0              0.2802   \n",
       "1        0.0              0.2776   \n",
       "2        0.0              0.2730   \n",
       "3        0.0              0.2689   \n",
       "4        0.0              0.2672   \n",
       "\n",
       "                                                text  \n",
       "0  .\\n#NYCACC\\n#DogsOfTwitter\\nROCKY\\n#ATTENTION\\...  \n",
       "1  #NYCACC\\n#DogsOfTwitter\\nCAPONE #VID\\n#ATTENTI...  \n",
       "2  <usernameremoved> I can't wait for the followi...  \n",
       "3  .\\n#NYCACC\\n#DogsOfTwitter\\nATLAS #VID\\n#ATTEN...  \n",
       "4  Apparently all my friends are talking about me...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_relevant_documents_collection_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1246"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(most_relevant_documents_collection_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get prepared data from each collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('../data/cambridge_analytica/regional_datasets/files_europe/english_europe_tweets_20190411_prepared_data_dict_with_more_info', 'rb') as f:\n",
    "    PreparedData_dict_with_more_info_collection_1 = pickle.load(f)\n",
    "topic_order_1 = PreparedData_dict_with_more_info_collection_1['topic.order']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mdsDat', 'tinfo', 'token.table', 'R', 'lambda.step', 'plot.opts', 'topic.order'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PreparedData_dict_with_more_info_collection_1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': [0.06561997262644692,\n",
       "  -0.28382506283890535,\n",
       "  -0.289401674780925,\n",
       "  0.21272859106268174,\n",
       "  0.14102093243196315,\n",
       "  0.1100277400167304,\n",
       "  -0.11840074227359862,\n",
       "  0.0961548131776081,\n",
       "  -0.022263868897948243,\n",
       "  0.13520202306311363,\n",
       "  -0.04686272358716678],\n",
       " 'y': [0.1128898003397685,\n",
       "  -0.09882663335825936,\n",
       "  0.004129310220773565,\n",
       "  -0.09558681479188345,\n",
       "  -0.12607354807849241,\n",
       "  0.12020526372784264,\n",
       "  -0.1473457220564188,\n",
       "  -0.017721932508940032,\n",
       "  -0.08350237935090149,\n",
       "  -0.06275473678850552,\n",
       "  0.39458739264501597],\n",
       " 'topics': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11],\n",
       " 'cluster': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " 'Freq': [9.276300185810001,\n",
       "  9.145722055493659,\n",
       "  9.12672005300048,\n",
       "  9.103953687112721,\n",
       "  9.084135700940731,\n",
       "  9.07681839621726,\n",
       "  9.070171684665636,\n",
       "  9.052063608257335,\n",
       "  9.051452269710127,\n",
       "  9.00923595607245,\n",
       "  9.003426402719588]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PreparedData_dict_with_more_info_collection_1['mdsDat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4, 1, 10, 9, 8, 11, 5, 6, 7]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_order_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('../data/cambridge_analytica/regional_datasets/files_europe/english_europe_tweets_20190411_prepared_data_dict_with_more_info', 'rb') as f:\n",
    "    PreparedData_dict_with_more_info_collection_2 = pickle.load(f)\n",
    "topic_order_2 = PreparedData_dict_with_more_info_collection_2['topic.order']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4, 1, 10, 9, 8, 11, 5, 6, 7]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_order_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': [0.06561997262644692,\n",
       "  -0.28382506283890535,\n",
       "  -0.289401674780925,\n",
       "  0.21272859106268174,\n",
       "  0.14102093243196315,\n",
       "  0.1100277400167304,\n",
       "  -0.11840074227359862,\n",
       "  0.0961548131776081,\n",
       "  -0.022263868897948243,\n",
       "  0.13520202306311363,\n",
       "  -0.04686272358716678],\n",
       " 'y': [0.1128898003397685,\n",
       "  -0.09882663335825936,\n",
       "  0.004129310220773565,\n",
       "  -0.09558681479188345,\n",
       "  -0.12607354807849241,\n",
       "  0.12020526372784264,\n",
       "  -0.1473457220564188,\n",
       "  -0.017721932508940032,\n",
       "  -0.08350237935090149,\n",
       "  -0.06275473678850552,\n",
       "  0.39458739264501597],\n",
       " 'topics': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11],\n",
       " 'cluster': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " 'Freq': [9.276300185810001,\n",
       "  9.145722055493659,\n",
       "  9.12672005300048,\n",
       "  9.103953687112721,\n",
       "  9.084135700940731,\n",
       "  9.07681839621726,\n",
       "  9.070171684665636,\n",
       "  9.052063608257335,\n",
       "  9.051452269710127,\n",
       "  9.00923595607245,\n",
       "  9.003426402719588]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PreparedData_dict_with_more_info_collection_2['mdsDat']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add relevance column to each dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevance_lambda = 0.6 #according to a user study, this is the best value. We can change this!!!\n",
    "\n",
    "\n",
    "tinfo_collection_1 = pd.DataFrame.from_dict(PreparedData_dict_with_more_info_collection_1['tinfo'])\n",
    "tinfo_collection_1['relevance'] = relevance_lambda * tinfo_collection_1['logprob']+ (1.00-relevance_lambda)*tinfo_collection_1['loglift']\n",
    "\n",
    "tinfo_collection_2 = pd.DataFrame.from_dict(PreparedData_dict_with_more_info_collection_2['tinfo'])\n",
    "tinfo_collection_2['relevance'] = relevance_lambda * tinfo_collection_2['logprob']+ (1.00-relevance_lambda)*tinfo_collection_2['loglift']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Freq</th>\n",
       "      <th>Term</th>\n",
       "      <th>Total</th>\n",
       "      <th>loglift</th>\n",
       "      <th>logprob</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Default</td>\n",
       "      <td>19023.0</td>\n",
       "      <td>datum</td>\n",
       "      <td>19023.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Default</td>\n",
       "      <td>10705.0</td>\n",
       "      <td>bigdata</td>\n",
       "      <td>10705.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Default</td>\n",
       "      <td>8660.0</td>\n",
       "      <td>privacy</td>\n",
       "      <td>8660.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Default</td>\n",
       "      <td>9296.0</td>\n",
       "      <td>facebook</td>\n",
       "      <td>9296.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Default</td>\n",
       "      <td>6147.0</td>\n",
       "      <td>user</td>\n",
       "      <td>6147.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category     Freq      Term    Total  loglift  logprob  relevance\n",
       "0  Default  19023.0     datum  19023.0     30.0     30.0       30.0\n",
       "1  Default  10705.0   bigdata  10705.0     29.0     29.0       29.0\n",
       "2  Default   8660.0   privacy   8660.0     28.0     28.0       28.0\n",
       "3  Default   9296.0  facebook   9296.0     27.0     27.0       27.0\n",
       "4  Default   6147.0      user   6147.0     26.0     26.0       26.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tinfo_collection_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Freq</th>\n",
       "      <th>Term</th>\n",
       "      <th>Total</th>\n",
       "      <th>loglift</th>\n",
       "      <th>logprob</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Default</td>\n",
       "      <td>19023.0</td>\n",
       "      <td>datum</td>\n",
       "      <td>19023.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Default</td>\n",
       "      <td>10705.0</td>\n",
       "      <td>bigdata</td>\n",
       "      <td>10705.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Default</td>\n",
       "      <td>8660.0</td>\n",
       "      <td>privacy</td>\n",
       "      <td>8660.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Default</td>\n",
       "      <td>9296.0</td>\n",
       "      <td>facebook</td>\n",
       "      <td>9296.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Default</td>\n",
       "      <td>6147.0</td>\n",
       "      <td>user</td>\n",
       "      <td>6147.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category     Freq      Term    Total  loglift  logprob  relevance\n",
       "0  Default  19023.0     datum  19023.0     30.0     30.0       30.0\n",
       "1  Default  10705.0   bigdata  10705.0     29.0     29.0       29.0\n",
       "2  Default   8660.0   privacy   8660.0     28.0     28.0       28.0\n",
       "3  Default   9296.0  facebook   9296.0     27.0     27.0       27.0\n",
       "4  Default   6147.0      user   6147.0     26.0     26.0       26.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tinfo_collection_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how get terms order by relevance\n",
    "'''\n",
    "topic_id = 0\n",
    "tinfo_collection_1.loc[tinfo_collection_1['Category'] == 'Topic'+str(topic_id+1)].sort_values(by='relevance', ascending=False)[['Term','relevance']][:n_terms]\n",
    "''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic similarity metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode\n",
    "import spacy\n",
    "\n",
    "from string import punctuation\n",
    "from gensim.utils import simple_preprocess\n",
    "from string import digits\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "stop_words = stopwords.words('english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''My own tokenizer '''\n",
    "\n",
    "punctuation+=\"¡¿<>'`\"\n",
    "punctuation+='\"'\n",
    "\n",
    "#Remove digits and puntuaction\n",
    "remove_digits = str.maketrans(digits, ' '*len(digits))#remove_digits = str.maketrans('', '', digits)\n",
    "remove_punctuation = str.maketrans(punctuation, ' '*len(punctuation))#remove_punctuation = str.maketrans('', '', punctuation)\n",
    "remove_hashtags_caracter = str.maketrans('#', ' '*len('#'))\n",
    "#las palabras de los hashtag se mantiene, pero no el simbolo. \n",
    "\n",
    "tknzr = TweetTokenizer()\n",
    "def sent_to_words(sentence):\n",
    "    return tknzr.tokenize(sentence)\n",
    "    \n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    doc = nlp(\" \".join(texts)) \n",
    "    texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out\n",
    "        \n",
    "def text_cleaner(tweet):\n",
    "    tweet = tweet.translate(remove_digits)\n",
    "    #tweet = tweet.lower() it wasn't a good idea,, we lost a lot of\n",
    "    tweet = tweet.translate(remove_punctuation)\n",
    "    tweet = tweet.translate(remove_hashtags_caracter)\n",
    "    tweet = tweet.lower()\n",
    "    tweet = unidecode.unidecode(tweet)\n",
    "    tweet = sent_to_words(tweet)\n",
    "    tweet = remove_stopwords(tweet)\n",
    "    new_tweet  = []\n",
    "    for elem in tweet:\n",
    "        if len(elem)>0:\n",
    "            new_tweet.append(elem[0])\n",
    "    tweet = lemmatization(new_tweet, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "    return tweet[0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['arrow', 'arrow']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_cleaner('This is a cooool #dummysmiley: :-) :-P <3 and some arrows < > -> <-- arrows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note, that vectors are going to be calculated according to topic order of PreparedData\n",
    "\n",
    "def get_dicts_relevant_keywords_documents(lda_model,df_relevant_documents, n_terms, topic_order, PreparedData_dict_with_more_info):\n",
    "    num_topics = lda_model.num_topics\n",
    "    #create dictionary of top keywords \n",
    "    topKeywordsDict = {}\n",
    "    for topic_id in range(num_topics):\n",
    "        \n",
    "        topKeywordsDict[topic_id] = []\n",
    "        \n",
    "        def save_relevant_keywords_in_dict(row):\n",
    "            topKeywordsDict[topic_id].append({  #el topic_id, debe ser segun el orden de lda_model\n",
    "                \"term\":row['Term'],\n",
    "                \"relevance\":row['relevance']\n",
    "            })\n",
    "            \n",
    "        topic_on_tinfo = topic_order.index(topic_id+1)+1    \n",
    "        PreparedData_dict_with_more_info.loc[PreparedData_dict_with_more_info['Category'] == 'Topic'+str(topic_on_tinfo)].sort_values(by='relevance', ascending=False)[['Term','relevance']][:n_terms].apply(save_relevant_keywords_in_dict, axis=1)    \n",
    "        \n",
    "        \n",
    "            \n",
    "    #create dictionary of relevant documents\n",
    "    relevantDocumentsDict = {}\n",
    "    \n",
    "    def save_relevant_documents_in_dict(row):\n",
    "        topic_id = int(row['Topic_Num'])\n",
    "        if topic_id not in relevantDocumentsDict:\n",
    "            relevantDocumentsDict[topic_id]=[]\n",
    "        relevantDocumentsDict[topic_id].append({\n",
    "            'topic_perc_contrib':row['Topic_Perc_Contrib'],\n",
    "            'text':row['text']\n",
    "        })\n",
    "        return None\n",
    "    \n",
    "    df_relevant_documents.apply(save_relevant_documents_in_dict, axis=1)\n",
    "    \n",
    "        \n",
    "    return (topKeywordsDict, relevantDocumentsDict)\n",
    "\n",
    "\n",
    "def getDocumentVector(text, wordembedding,  topic_id , topic_order, PreparedData_dict_with_more_info):\n",
    "    #preprocesar    \n",
    "    #encontrar palabras en word embedding\n",
    "    #ponderas palabras with relevance metric\n",
    "    \n",
    "    topic_on_tinfo = topic_order.index(topic_id+1)+1    \n",
    "    list_terms_relevance = PreparedData_dict_with_more_info.loc[PreparedData_dict_with_more_info['Category'] == 'Topic'+str(topic_on_tinfo)].sort_values(by='relevance', ascending=False)['Term'].tolist()\n",
    "    document_vector = 0.0\n",
    "    words_found = set()\n",
    "    for word in text_cleaner(text):    \n",
    "        if word in list_terms_relevance:\n",
    "            raking_word = float(list_terms_relevance.index(word)+1)\n",
    "            if word in wordembedding.wv:\n",
    "                #print(\"WORD FOUND\", word)\n",
    "                document_vector+=wordembedding.wv[word]/raking_word #aqui hay que ponderar\n",
    "                words_found.add(word.upper())\n",
    "            else:\n",
    "                print(\"WARNING, Word not found:\", word)\n",
    "        #else:\n",
    "        #    print(\"not found word\", word.upper(), \"for document:\",text_cleaner(text))\n",
    "    #print(\"words found\", words_found)\n",
    "    return document_vector\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "def get_topkeywords_relevantdocuments_vectors(wordembedding, lda_model,most_relevant_documents,  n_terms, topic_order, PreparedData_dict_with_more_info, topkdocuments): #n_terms : numero de top keywords a considerar\n",
    "    topKeywordsDict, relevantDocumentsDict = get_dicts_relevant_keywords_documents(lda_model, most_relevant_documents, n_terms, topic_order,  PreparedData_dict_with_more_info)\n",
    "\n",
    "    ##Create top keyword vector per topic\n",
    "    topkeywords_vectors_dict = {}\n",
    "    num_topics = lda_model.num_topics\n",
    "    for topic_id in range(num_topics):\n",
    "        topkeywords_vector = 0\n",
    "        ranking = 1.0\n",
    "        for item in topKeywordsDict[topic_id]:\n",
    "            if item['term'] in wordembedding.wv: \n",
    "                topkeywords_vector += wordembedding.wv[item['term']]/ranking\n",
    "            else:\n",
    "                print(\"WARNING NOT FOUND: \", item['term'],\" position:\",ranking)\n",
    "            ranking+=1\n",
    "        topkeywords_vectors_dict[topic_id] = topkeywords_vector\n",
    "        \n",
    "    #Create a top relevant document vector    \n",
    "    relevantdocuments_vectors_dict = {}\n",
    "    for topic_id in range(num_topics):\n",
    "        relevantDocumentsvector = 0.0\n",
    "        j = 0\n",
    "        for item in relevantDocumentsDict[topic_id][0:topkdocuments]: #we consider only the most k documents.             \n",
    "            j+=1                                            \n",
    "            relevantDocumentsvector+= float(item['topic_perc_contrib'])*getDocumentVector(item['text'], wordembedding, topic_id, topic_order, PreparedData_dict_with_more_info) #PODRIA HACER UNA ESPECIE DE RANKING, SIMILAR A LO QUE HICE CON LAS TOP KEYWORDS.\n",
    "        relevantdocuments_vectors_dict[topic_id] = relevantDocumentsvector\n",
    "        \n",
    "    return (topkeywords_vectors_dict, relevantdocuments_vectors_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here, we calculate once the topkeywords_vector and the relevant documents_vector for each topic\n",
    "#We are going to calculate several times:      #final topic vector = (lambda)topic_keyword_vector + (lambda-1)topic_document_vector\n",
    "#because we are going to try different lambda (between 0 and 1)\n",
    "def get_topic_vectors(wordembedding, lda_model,most_relevant_documents,  n_terms, lambda_, topic_order, PreparedData_dict_with_more_info, topkdocuments):\n",
    "    num_topics = lda_model.num_topics\n",
    "    topkeywords_vectors_dict, relevantdocuments_vectors_dict = get_topkeywords_relevantdocuments_vectors(wordembedding, lda_model,most_relevant_documents,  n_terms, topic_order, PreparedData_dict_with_more_info, topkdocuments)\n",
    "    final_topic_vectors_dict = dict()\n",
    "    for topic_id in range(num_topics):\n",
    "        final_topic_vector = lambda_*topkeywords_vectors_dict[topic_id]+(1-lambda_)*relevantdocuments_vectors_dict[topic_id]\n",
    "        final_topic_vectors_dict[topic_id] = final_topic_vector\n",
    "    return final_topic_vectors_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This matrix is calculated by a specific lambda. \n",
    "def get_matrix(wordembedding, lda_model_1,most_relevant_documents_1,lda_model_2,most_relevant_documents_2, n_terms, lambda_, topic_order_1, topic_order_2, PreparedData_dict_with_more_info_1, PreparedData_dict_with_more_info_2, topkdocuments):\n",
    "    \n",
    "    #final topic vector = (lambda)topic_keyword_vector + (lambda-1)topic_document_vector\n",
    "    final_topic_vectors_dict_1 =  get_topic_vectors(wordembedding, lda_model_1,most_relevant_documents_1,  n_terms, lambda_, topic_order_1, PreparedData_dict_with_more_info_1, topkdocuments)\n",
    "    final_topic_vectors_dict_2 =  get_topic_vectors(wordembedding, lda_model_2,most_relevant_documents_2,  n_terms, lambda_, topic_order_2,  PreparedData_dict_with_more_info_2, topkdocuments)\n",
    "    \n",
    "    topic_similarity_matrix = []\n",
    "    for i in range(lda_model_1.num_topics):\n",
    "        row = []\n",
    "        for j in range(lda_model_2.num_topics):\n",
    "            topic_i = final_topic_vectors_dict_1[i].reshape(1,-1)\n",
    "            topic_j = final_topic_vectors_dict_2[j].reshape(1,-1)\n",
    "            row.append(float(cosine_similarity(topic_i,topic_j)))\n",
    "            #print(i,j,float(cosine_similarity(topic_i,topic_j)))\n",
    "        topic_similarity_matrix.append(row)\n",
    "    topic_similarity_matrix= np.asarray(topic_similarity_matrix)\n",
    "    return topic_similarity_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.01\n",
      "0.02\n",
      "0.03\n",
      "0.04\n",
      "0.05\n",
      "0.06\n",
      "0.07\n",
      "0.08\n",
      "0.09\n",
      "0.1\n",
      "0.11\n",
      "0.12\n",
      "0.13\n",
      "0.14\n",
      "0.15\n",
      "0.16\n",
      "0.17\n",
      "0.18\n",
      "0.19\n",
      "0.2\n",
      "0.21\n",
      "0.22\n",
      "0.23\n",
      "0.24\n",
      "0.25\n",
      "0.26\n",
      "0.27\n",
      "0.28\n",
      "0.29\n",
      "0.3\n",
      "0.31\n",
      "0.32\n",
      "0.33\n",
      "0.34\n",
      "0.35\n",
      "0.36\n",
      "0.37\n",
      "0.38\n",
      "0.39\n",
      "0.4\n",
      "0.41\n",
      "0.42\n",
      "0.43\n",
      "0.44\n",
      "0.45\n",
      "0.46\n",
      "0.47\n",
      "0.48\n",
      "0.49\n",
      "0.5\n",
      "0.51\n",
      "0.52\n",
      "0.53\n",
      "0.54\n",
      "0.55\n",
      "0.56\n",
      "0.57\n",
      "0.58\n",
      "0.59\n",
      "0.6\n",
      "0.61\n",
      "0.62\n",
      "0.63\n",
      "0.64\n",
      "0.65\n",
      "0.66\n",
      "0.67\n",
      "0.68\n",
      "0.69\n",
      "0.7\n",
      "0.71\n",
      "0.72\n",
      "0.73\n",
      "0.74\n",
      "0.75\n",
      "0.76\n",
      "0.77\n",
      "0.78\n",
      "0.79\n",
      "0.8\n",
      "0.81\n",
      "0.82\n",
      "0.83\n",
      "0.84\n",
      "0.85\n",
      "0.86\n",
      "0.87\n",
      "0.88\n",
      "0.89\n",
      "0.9\n",
      "0.91\n",
      "0.92\n",
      "0.93\n",
      "0.94\n",
      "0.95\n",
      "0.96\n",
      "0.97\n",
      "0.98\n",
      "0.99\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "topn = 20\n",
    "topkdocuments = 20\n",
    "#lambda_ = 0.8\n",
    "\n",
    "\n",
    "#i = 0.0\n",
    "i = 0.0\n",
    "matrices_dict = dict()\n",
    "while i <=1.01:\n",
    "    lambda_ = round(i*100/100,2)\n",
    "    print(lambda_)\n",
    "    matrix = get_matrix(wordembedding, lda_model_collecion_1, most_relevant_documents_collection_1, lda_model_collecion_2, most_relevant_documents_collection_2,topn, lambda_, topic_order_1, topic_order_2, tinfo_collection_1, tinfo_collection_2, topkdocuments)\n",
    "    matrices_dict[lambda_] = matrix\n",
    "    i+=0.01\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/cambridge_analytica/regional_datasets/matrix_europe_vs_europe_own_wordembedding_final', 'wb') as f:\n",
    "            pickle.dump(matrices_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "with open('../data/cambridge_analytica/regional_datasets/matrix_europe_vs_northamerica_own_wordembedding_final', 'wb') as f:\n",
    "            pickle.dump(matrices_dict, f)\n",
    "''';"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
