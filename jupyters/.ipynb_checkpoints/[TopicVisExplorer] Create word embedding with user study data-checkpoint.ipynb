{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gensim\n",
    "import gensim\n",
    "import spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gonza\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import os.path\n",
    "import glob\n",
    "import re\n",
    "from xml.dom import minidom\n",
    "import nltk\n",
    "import nltk\n",
    "import gensim\n",
    "import random\n",
    "import numpy as np\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import random\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "%pprint \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import keras\n",
    "#import keras.preprocessing.sequence as seq\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot\n",
    "#from keras.layers import Input, Activation\n",
    "#from keras.models import Model\n",
    "#from keras.layers.embeddings import Embedding\n",
    "from gensim import models\n",
    "from scipy import spatial\n",
    "from datetime import datetime\n",
    "from string import digits\n",
    "from string import punctuation\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['linkremoved',' <link removed>','usernameremoved','<usernameremoved>','<linkremoved>','usernameremoved_usernameremoved','linkremoved_linkremoved'])\n",
    "##stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1  = pd.read_csv('../data/cambridge_analytica/regional_datasets/english_northamerica_tweets_20190411.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "342400"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2  = pd.read_csv('../data/cambridge_analytica/regional_datasets/english_europe_tweets_20190411.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111745"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "454145"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df) == (len(df1)+len(df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['texto_completo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>created_at2</th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>user.screen_name</th>\n",
       "      <th>user_location</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>text</th>\n",
       "      <th>full_text</th>\n",
       "      <th>retweet_created_at</th>\n",
       "      <th>retweet_full_text</th>\n",
       "      <th>texto_completo</th>\n",
       "      <th>ubicacion_encontrada</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>id-980480936205783047</td>\n",
       "      <td>Sun Apr 01 16:24:06 +0000 2018</td>\n",
       "      <td>stanscott53</td>\n",
       "      <td>Coldspring, TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;usernameremoved&gt; Hold Facebook accountable fo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;usernameremoved&gt; Hold Facebook accountable fo...</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>id-980481012550524928</td>\n",
       "      <td>Sun Apr 01 16:24:24 +0000 2018</td>\n",
       "      <td>RShaffer1</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Both sides should just drop it. Trump won...el...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Both sides should just drop it. Trump won...el...</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>id-980480980191404032</td>\n",
       "      <td>Sun Apr 01 16:24:16 +0000 2018</td>\n",
       "      <td>pcampisi14</td>\n",
       "      <td>Toronto, Ontario</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$AAPL lobbing threes while they can. Wasnt it ...</td>\n",
       "      <td>$AAPL lobbing threes while they can. Wasnt it ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$AAPL lobbing threes while they can. Wasnt it ...</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>id-980481205492682753</td>\n",
       "      <td>Sun Apr 01 16:25:10 +0000 2018</td>\n",
       "      <td>CoinSignalBot</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15 min #RSI Signals:\\n\\n$BTC - $SLR: 6.84\\n$BT...</td>\n",
       "      <td>15 min #RSI Signals:\\n\\n$BTC - $SLR: 6.84\\n$BT...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15 min #RSI Signals:\\n\\n$BTC - $SLR: 6.84\\n$BT...</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>id-980481164334063616</td>\n",
       "      <td>Sun Apr 01 16:25:00 +0000 2018</td>\n",
       "      <td>kimbee802009</td>\n",
       "      <td>South Dakota, USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;usernameremoved&gt; Hold Facebook accountable fo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;usernameremoved&gt; Hold Facebook accountable fo...</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 created_at2                     id  \\\n",
       "0           1  2018-04-01  id-980480936205783047   \n",
       "1           6  2018-04-01  id-980481012550524928   \n",
       "2           9  2018-04-01  id-980480980191404032   \n",
       "3          16  2018-04-01  id-980481205492682753   \n",
       "4          20  2018-04-01  id-980481164334063616   \n",
       "\n",
       "                       created_at user.screen_name      user_location  \\\n",
       "0  Sun Apr 01 16:24:06 +0000 2018      stanscott53     Coldspring, TX   \n",
       "1  Sun Apr 01 16:24:24 +0000 2018        RShaffer1         Boston, MA   \n",
       "2  Sun Apr 01 16:24:16 +0000 2018       pcampisi14   Toronto, Ontario   \n",
       "3  Sun Apr 01 16:25:10 +0000 2018    CoinSignalBot        Seattle, WA   \n",
       "4  Sun Apr 01 16:25:00 +0000 2018     kimbee802009  South Dakota, USA   \n",
       "\n",
       "  coordinates                                               text  \\\n",
       "0         NaN  <usernameremoved> Hold Facebook accountable fo...   \n",
       "1         NaN  Both sides should just drop it. Trump won...el...   \n",
       "2         NaN  $AAPL lobbing threes while they can. Wasnt it ...   \n",
       "3         NaN  15 min #RSI Signals:\\n\\n$BTC - $SLR: 6.84\\n$BT...   \n",
       "4         NaN  <usernameremoved> Hold Facebook accountable fo...   \n",
       "\n",
       "                                           full_text  retweet_created_at  \\\n",
       "0                                                NaN                 NaN   \n",
       "1                                                NaN                 NaN   \n",
       "2  $AAPL lobbing threes while they can. Wasnt it ...                 NaN   \n",
       "3  15 min #RSI Signals:\\n\\n$BTC - $SLR: 6.84\\n$BT...                 NaN   \n",
       "4                                                NaN                 NaN   \n",
       "\n",
       "   retweet_full_text                                     texto_completo  \\\n",
       "0                NaN  <usernameremoved> Hold Facebook accountable fo...   \n",
       "1                NaN  Both sides should just drop it. Trump won...el...   \n",
       "2                NaN  $AAPL lobbing threes while they can. Wasnt it ...   \n",
       "3                NaN  15 min #RSI Signals:\\n\\n$BTC - $SLR: 6.84\\n$BT...   \n",
       "4                NaN  <usernameremoved> Hold Facebook accountable fo...   \n",
       "\n",
       "  ubicacion_encontrada  \n",
       "0        United States  \n",
       "1        United States  \n",
       "2               Canada  \n",
       "3        United States  \n",
       "4        United States  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remove links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'].replace({\"http\\\\S+\": '<linkremoved>'}, inplace=True, regex=True)\n",
    "df['text'].replace({\"<link removed>\": '<linkremoved>'}, inplace=True, regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<usernameremoved> Hold Facebook accountable for abusing our data and censoring our voice. Vote no on the CRA. <linkremoved>\n",
      "Both sides should just drop it. Trump won...elections over. Move on. <linkremoved>\n",
      "$AAPL lobbing threes while they can. Wasnt it just a few years back when their platform was actually hacked and people private photos were exposed? <linkremoved>\n",
      "15 min #RSI Signals:\n",
      "\n",
      "$BTC - $SLR: 6.84\n",
      "$BTC - $OMNI: 6.97\n",
      "$BTC - $RBY: 6.99\n",
      "$BTC - $SPHR: 21.13\n",
      "$BTC - $RDN: 21.17\n",
      "$BTC - $MCO: 21.48\n",
      "$BTC - $VIBE: 23.76\n",
      "$BTC - $ADX: 26.25\n",
      "$BTC - $PPT: 26.63\n",
      "\n",
      "#Bitcoin #tokensale #smartcontract #ETH #DAPP $LTC #signals #RADS #BigData #litecoin\n",
      "<usernameremoved> Hold Facebook accountable for abusing our data and censoring our voice. Vote no on the CRA.\n",
      "\n",
      "<linkremoved>\n"
     ]
    }
   ],
   "source": [
    "for texto in df['text'][0:5]:\n",
    "    print(texto)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>created_at2</th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>user.screen_name</th>\n",
       "      <th>user_location</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>text</th>\n",
       "      <th>full_text</th>\n",
       "      <th>retweet_created_at</th>\n",
       "      <th>retweet_full_text</th>\n",
       "      <th>texto_completo</th>\n",
       "      <th>ubicacion_encontrada</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>id-980480936205783047</td>\n",
       "      <td>Sun Apr 01 16:24:06 +0000 2018</td>\n",
       "      <td>stanscott53</td>\n",
       "      <td>Coldspring, TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;usernameremoved&gt; Hold Facebook accountable fo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;usernameremoved&gt; Hold Facebook accountable fo...</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>id-980481012550524928</td>\n",
       "      <td>Sun Apr 01 16:24:24 +0000 2018</td>\n",
       "      <td>RShaffer1</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Both sides should just drop it. Trump won...el...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Both sides should just drop it. Trump won...el...</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>id-980480980191404032</td>\n",
       "      <td>Sun Apr 01 16:24:16 +0000 2018</td>\n",
       "      <td>pcampisi14</td>\n",
       "      <td>Toronto, Ontario</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$AAPL lobbing threes while they can. Wasnt it ...</td>\n",
       "      <td>$AAPL lobbing threes while they can. Wasnt it ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$AAPL lobbing threes while they can. Wasnt it ...</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>id-980481205492682753</td>\n",
       "      <td>Sun Apr 01 16:25:10 +0000 2018</td>\n",
       "      <td>CoinSignalBot</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15 min #RSI Signals:\\n\\n$BTC - $SLR: 6.84\\n$BT...</td>\n",
       "      <td>15 min #RSI Signals:\\n\\n$BTC - $SLR: 6.84\\n$BT...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15 min #RSI Signals:\\n\\n$BTC - $SLR: 6.84\\n$BT...</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>id-980481164334063616</td>\n",
       "      <td>Sun Apr 01 16:25:00 +0000 2018</td>\n",
       "      <td>kimbee802009</td>\n",
       "      <td>South Dakota, USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;usernameremoved&gt; Hold Facebook accountable fo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;usernameremoved&gt; Hold Facebook accountable fo...</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 created_at2                     id  \\\n",
       "0           1  2018-04-01  id-980480936205783047   \n",
       "1           6  2018-04-01  id-980481012550524928   \n",
       "2           9  2018-04-01  id-980480980191404032   \n",
       "3          16  2018-04-01  id-980481205492682753   \n",
       "4          20  2018-04-01  id-980481164334063616   \n",
       "\n",
       "                       created_at user.screen_name      user_location  \\\n",
       "0  Sun Apr 01 16:24:06 +0000 2018      stanscott53     Coldspring, TX   \n",
       "1  Sun Apr 01 16:24:24 +0000 2018        RShaffer1         Boston, MA   \n",
       "2  Sun Apr 01 16:24:16 +0000 2018       pcampisi14   Toronto, Ontario   \n",
       "3  Sun Apr 01 16:25:10 +0000 2018    CoinSignalBot        Seattle, WA   \n",
       "4  Sun Apr 01 16:25:00 +0000 2018     kimbee802009  South Dakota, USA   \n",
       "\n",
       "  coordinates                                               text  \\\n",
       "0         NaN  <usernameremoved> Hold Facebook accountable fo...   \n",
       "1         NaN  Both sides should just drop it. Trump won...el...   \n",
       "2         NaN  $AAPL lobbing threes while they can. Wasnt it ...   \n",
       "3         NaN  15 min #RSI Signals:\\n\\n$BTC - $SLR: 6.84\\n$BT...   \n",
       "4         NaN  <usernameremoved> Hold Facebook accountable fo...   \n",
       "\n",
       "                                           full_text  retweet_created_at  \\\n",
       "0                                                NaN                 NaN   \n",
       "1                                                NaN                 NaN   \n",
       "2  $AAPL lobbing threes while they can. Wasnt it ...                 NaN   \n",
       "3  15 min #RSI Signals:\\n\\n$BTC - $SLR: 6.84\\n$BT...                 NaN   \n",
       "4                                                NaN                 NaN   \n",
       "\n",
       "   retweet_full_text                                     texto_completo  \\\n",
       "0                NaN  <usernameremoved> Hold Facebook accountable fo...   \n",
       "1                NaN  Both sides should just drop it. Trump won...el...   \n",
       "2                NaN  $AAPL lobbing threes while they can. Wasnt it ...   \n",
       "3                NaN  15 min #RSI Signals:\\n\\n$BTC - $SLR: 6.84\\n$BT...   \n",
       "4                NaN  <usernameremoved> Hold Facebook accountable fo...   \n",
       "\n",
       "  ubicacion_encontrada  \n",
       "0        United States  \n",
       "1        United States  \n",
       "2               Canada  \n",
       "3        United States  \n",
       "4        United States  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remove usernames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'].replace({\"@[^\\\\s]+\": '<usernameremoved>'}, inplace=True, regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(['text'],keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "454145"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190646"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numero de usuarios\n",
    "tweets_by_user_data = df.groupby('user.screen_name').agg('size').sort_values(ascending=False).reset_index()\n",
    "len(tweets_by_user_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remove digits, punctuation, symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "punctuation+='¡¿'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove digits and puntuaction\n",
    "remove_digits = str.maketrans(digits, ' '*len(digits))#remove_digits = str.maketrans('', '', digits)\n",
    "remove_punctuation = str.maketrans(punctuation, ' '*len(punctuation))#remove_punctuation = str.maketrans('', '', punctuation)\n",
    "remove_hashtags_caracter = str.maketrans('#', ' '*len('#'))\n",
    "#las palabras de los hashtag se mantiene, pero no el simbolo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import unidecode\n",
    "\n",
    "data = []\n",
    "for tweet in df['text']:\n",
    "    tweet = tweet.translate(remove_digits)\n",
    "    #tweet = tweet.lower() it wasn't a good idea,, we lost a lot of\n",
    "    tweet = tweet.translate(remove_punctuation)\n",
    "    tweet = tweet.translate(remove_hashtags_caracter)\n",
    "    tweet = tweet.lower()\n",
    "    tweet = unidecode.unidecode(tweet)\n",
    "    #tweet = tweet.strip().split()\n",
    "    #filtered_words = [word for word in tweet if word not in stopWords]\n",
    "    #corpus[id_tweet]= filtered_words\n",
    "    #id_tweet+=1\n",
    "    data.append(tweet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' usernameremoved  hold facebook accountable for abusing our data and censoring our voice  vote no on the cra   linkremoved ', 'both sides should just drop it  trump won   elections over  move on   linkremoved ', ' aapl lobbing threes while they can  wasnt it just a few years back when their platform was actually hacked and people private photos were exposed   linkremoved ', '   min  rsi signals \\n\\n btc    slr      \\n btc    omni      \\n btc    rby      \\n btc    sphr       \\n btc    rdn       \\n btc    mco       \\n btc    vibe       \\n btc    adx       \\n btc    ppt       \\n\\n bitcoin  tokensale  smartcontract  eth  dapp  ltc  signals  rads  bigdata  litecoin', ' usernameremoved  hold facebook accountable for abusing our data and censoring our voice  vote no on the cra \\n\\n linkremoved ']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "454145"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tknzr = TweetTokenizer()\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(tknzr.tokenize(sentence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_words = list(sent_to_words(data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create bigram and trigram models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['both', 'sides', 'should', 'just', 'drop', 'it', 'trump', 'won', 'elections', 'over', 'move', 'on', 'linkremoved']\n"
     ]
    }
   ],
   "source": [
    "# Build the bigram and trigram models\n",
    "#quizas el min count es muy bajo\n",
    "#documentaicon de bigramas \n",
    "#https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/#3importpackages\n",
    "min_count = int(len(df)*0.02)\n",
    "bigram = gensim.models.Phrases(data_words, min_count=min_count, threshold=1) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], min_count =min_count, threshold=1)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# See trigram example\n",
    "print(trigram_mod[bigram_mod[data_words[1]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['usernameremoved', 'hold', 'facebook', 'accountable', 'for', 'abusing', 'our', 'data', 'and', 'censoring', 'our', 'voice', 'vote', 'no', 'on', 'the', 'cra', 'linkremoved']\n",
      "['both', 'sides', 'should', 'just', 'drop', 'it', 'trump', 'won', 'elections', 'over', 'move', 'on', 'linkremoved']\n",
      "['aapl', 'lobbing', 'threes', 'while', 'they', 'can', 'wasnt', 'it', 'just', 'a', 'few', 'years', 'back', 'when', 'their', 'platform', 'was', 'actually', 'hacked', 'and', 'people', 'private', 'photos', 'were', 'exposed', 'linkremoved']\n",
      "['min', 'rsi', 'signals', 'btc', 'slr', 'btc', 'omni', 'btc', 'rby', 'btc', 'sphr', 'btc', 'rdn', 'btc', 'mco', 'btc', 'vibe', 'btc', 'adx', 'btc', 'ppt', 'bitcoin', 'tokensale', 'smartcontract', 'eth', 'dapp', 'ltc', 'signals', 'rads', 'bigdata', 'litecoin']\n",
      "['usernameremoved', 'hold', 'facebook', 'accountable', 'for', 'abusing', 'our', 'data', 'and', 'censoring', 'our', 'voice', 'vote', 'no', 'on', 'the', 'cra', 'linkremoved']\n"
     ]
    }
   ],
   "source": [
    "# See trigram example\n",
    "#print(trigram_mod[bigram_mod[data_words[1]]])\n",
    "for i in range(0,5):\n",
    "    print(trigram_mod[bigram_mod[data_words[i]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove stopwords, make bigrams and lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hold', 'facebook', 'accountable', 'abusing', 'data', 'censoring', 'voice', 'vote', 'cra']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_words_nostops[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gonza\\tesisenv\\Scripts\\python.exe: No module named spacy\n"
     ]
    }
   ],
   "source": [
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['hold', 'accountable', 'abusing', 'datum', 'censor', 'voice', 'vote']]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#sera mejor ocupar wordnetlemattizer?\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(data_lemmatized[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hold', 'accountable', 'abusing', 'datum', 'censor', 'voice', 'vote']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lemmatized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#texts should be a list of list, where each sublist is a lemmatized sentence\n",
    "texts = data_lemmatized\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "454145"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['hold', 'accountable', 'abusing', 'datum', 'censor', 'voice', 'vote'], ['side', 'drop', 'trump', 'election', 'move'], ['lob', 'three', 'year', 'back', 'platform', 'actually', 'hack', 'people', 'private', 'photo', 'expose'], ['signal', 'rad', 'bigdata'], ['hold', 'accountable', 'abusing', 'datum', 'censor', 'voice', 'vote'], ['lmfao'], ['user', 'lock', 'horse', 'go'], ['worried', 'ethic', 'lol'], ['ship', 'even', 'trust', 'much', 'get', 'tired'], ['sell', 'dietary', 'habit', 'know', 'eat', 'frozen']]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vocabulario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are:67706\n"
     ]
    }
   ],
   "source": [
    "conjunto_palabras = set()\n",
    "for sentence in texts:\n",
    "    for term in sentence:\n",
    "        conjunto_palabras.add(term)\n",
    "print(\"There are:\"+str(len(conjunto_palabras)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deletefacebook in set: True\n",
      "retweete in set: True\n",
      "gdpr in set: True\n",
      "socialmedia in set: True\n",
      "bigdata in set: True\n",
      "machinelearne in set: True\n",
      "datascience in set: True\n",
      "deeplearne in set: True\n",
      "retweeted in set: True\n"
     ]
    }
   ],
   "source": [
    "list_terms_that_may_not_appear = ['deletefacebook', 'retweete', 'gdpr', 'socialmedia', 'bigdata','machinelearne', 'datascience', 'deeplearne', 'retweeted']\n",
    "for term in list_terms_that_may_not_appear:\n",
    "    print(term, \"in set:\", term in conjunto_palabras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# crear word embeddings - best architecture so far according to EPJ data science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tweets: 454145\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of tweets: \"+str(len(texts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 0:02:26.684719\n"
     ]
    }
   ],
   "source": [
    "#https://colab.research.google.com/drive/1c0KFI1FEFNnfmKWrBFpR2GGI76_d0rg0?authuser=1#scrollTo=Y_CF5UpqPXuf\n",
    "start_time = datetime.now()\n",
    "model_created = Word2Vec(texts, size=300, iter = 50, sg=0, window=5, workers=4, negative =5, compute_loss=True, min_count=3) #min_count permite hacer un trim\n",
    "end_time = datetime.now()\n",
    "print('Duration: {}'.format(end_time - start_time))\n",
    "#https://docs.google.com/spreadsheets/d/1qhTmk3xxMW-NGLO2ZlvwSYzv7sI5i3RwlsIZAaY5Ndc/edit#gid=1606388650\n",
    "model_created.save('embedding_english_europe_northamerica_word2vec_300dimensions_cbow_trim3_epoch50.model')\n",
    "model_created.wv.save_word2vec_format('embedding_english__europe_northamerica_word2vec_300dimensions_cbow_trim3_epoch50.bin',binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://docs.google.com/spreadsheets/d/1F0HHOTjnQxmV2vQjMrKo_9RXoeoF8Nw59R1vXsX5tVM/edit#gid=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deletefacebook in set: True\n",
      "retweete in set: True\n",
      "gdpr in set: True\n",
      "socialmedia in set: True\n",
      "bigdata in set: True\n",
      "machinelearne in set: True\n",
      "datascience in set: True\n",
      "deeplearne in set: True\n",
      "retweeted in set: True\n"
     ]
    }
   ],
   "source": [
    "list_terms_that_may_not_appear = ['deletefacebook', 'retweete', 'gdpr', 'socialmedia', 'bigdata','machinelearne', 'datascience', 'deeplearne', 'retweeted']\n",
    "for term in list_terms_that_may_not_appear:\n",
    "    print(term, \"in set:\", term in model_created.wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
