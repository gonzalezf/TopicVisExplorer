{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import topicvisexplorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(topicvisexplorer)\n",
    "vis = topicvisexplorer.TopicVisExplorer(\"name\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BUSCAR EL DATASET DE AIRLINES CON TOPIC SPLITTING EL QUE ES CON MENOS TOPICO!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded sucessfully\n"
     ]
    }
   ],
   "source": [
    "#Single corpus data \n",
    "\n",
    "#vis.load_single_corpus_data(\"models_output/single_corpus_airlines_dataset.pkl\",  human_in_the_loop = False)\n",
    "vis.load_single_corpus_data(\"models_output/single_corpus_airlines_dataset.pkl\",  human_in_the_loop = True)\n",
    "\n",
    "\n",
    "#vis.load_single_corpus_data(\"models_output/single_corpus_europe_dataset_topics_6.pkl\", human_in_the_loop = True)\n",
    "#vis.load_single_corpus_data(\"models_output/single_corpus_europe_dataset_topics_6.pkl\", human_in_the_loop = True)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multicorpora datasets\n",
    "\n",
    "#vis.load_multi_corpora_data(\"models_output/multi_corpora_data_airlines_dataset.pkl\")\n",
    "#vis.load_multi_corpora_data(\"models_output/multi_corpora_data_airlines_dataset_baseline_metric.pkl\")\n",
    "\n",
    "#vis.load_multi_corpora_data(\"models_output/multi_corpora_data_europe_northamerica_ca_lda_mallet_gensim.pkl\")\n",
    "#vis.load_multi_corpora_data(\"models_output/multi_corpora_data_europe_northamerica_ca_lda_mallet_gensim_topic_similarity_baseline.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"name\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estoy en la funcion single corpuuuus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [05/Apr/2021 11:49:17] \"\u001b[37mGET /singlecorpus HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [05/Apr/2021 11:49:18] \"\u001b[37mGET /static/js/popper.min.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [05/Apr/2021 11:49:18] \"\u001b[37mGET /static/js/jquery.min.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [05/Apr/2021 11:49:18] \"\u001b[37mGET /static/css/bootstrap.min.css HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [05/Apr/2021 11:49:18] \"\u001b[37mGET /static/css/LDAvis.css HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [05/Apr/2021 11:49:18] \"\u001b[37mGET /static/fontawesome/css/solid.css HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [05/Apr/2021 11:49:18] \"\u001b[37mGET /static/fontawesome/css/fontawesome.css HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [05/Apr/2021 11:49:18] \"\u001b[37mGET /static/fontawesome/css/brands.css HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [05/Apr/2021 11:49:18] \"\u001b[37mGET /static/css/bootstrap-table.min.css HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [05/Apr/2021 11:49:18] \"\u001b[37mGET /static/css/nouislider.css HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [05/Apr/2021 11:49:18] \"\u001b[37mGET /static/bootstrap-slider/dist/css/bootstrap-slider.css HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [05/Apr/2021 11:49:18] \"\u001b[37mGET /static/jquery-checkradios-master/css/jquery.checkradios.min.css HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [05/Apr/2021 11:49:18] \"\u001b[37mGET /static/intro-js/introjs.min.css HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [05/Apr/2021 11:49:18] \"\u001b[37mGET /static/js/bootstrap.min.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [05/Apr/2021 11:49:18] \"\u001b[37mGET /static/js/d3.v5.min.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [05/Apr/2021 11:49:19] \"\u001b[37mGET /static/js/sankey.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [05/Apr/2021 11:49:19] \"\u001b[37mGET /static/js/xlsx.full.min.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [05/Apr/2021 11:49:19] \"\u001b[37mGET /static/js/FileSaver.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [05/Apr/2021 11:49:19] \"\u001b[37mGET /static/js/nouislider.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [05/Apr/2021 11:49:19] \"\u001b[37mGET /static/js/lodash.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [05/Apr/2021 11:49:19] \"\u001b[37mGET /static/bootstrap-slider/dist/bootstrap-slider.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [05/Apr/2021 11:49:19] \"\u001b[37mGET /static/jquery-checkradios-master/js/jquery.checkradios.min.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [05/Apr/2021 11:49:19] \"\u001b[37mGET /static/intro-js/intro.min.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [05/Apr/2021 11:49:19] \"\u001b[37mGET /static/js/bootstrap-table.long.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [05/Apr/2021 11:49:19] \"\u001b[33mGET /static/js/popper.min.js.map HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [05/Apr/2021 11:49:19] \"\u001b[33mGET /static/js/bootstrap.min.js.map HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [05/Apr/2021 11:49:19] \"\u001b[33mGET /static/css/bootstrap.min.css.map HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [05/Apr/2021 11:49:19] \"\u001b[33mGET /static/bootstrap-slider/dist/css/bootstrap-slider.css.map HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [05/Apr/2021 11:49:20] \"\u001b[37mGET /static/js/LDAvis.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [05/Apr/2021 11:49:20] \"\u001b[33mGET /static/intro-js/introjs.min.css.map HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [05/Apr/2021 11:49:20] \"\u001b[37mGET /SingleCorpus_documents HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [05/Apr/2021 11:49:20] \"\u001b[37mGET /static/fontawesome/webfonts/fa-solid-900.woff2 HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [05/Apr/2021 11:49:20] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [05/Apr/2021 11:49:31] \"\u001b[37mPOST /export_user_study_data HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single corpus data saved sucessfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [05/Apr/2021 11:50:21] \"\u001b[37mPOST /export_user_study_data HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single corpus data saved sucessfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [05/Apr/2021 11:50:50] \"\u001b[37mPOST /export_user_study_data HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single corpus data saved sucessfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [05/Apr/2021 11:51:13] \"\u001b[37mPOST /export_user_study_data HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single corpus data saved sucessfully\n"
     ]
    }
   ],
   "source": [
    "vis.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_id, write_ipynb_local_js, NumPyEncoder\n",
    "\n",
    "import json as js\n",
    "\n",
    "\n",
    "new_dict = dict()\n",
    "data = [topicvisexplorer.single_corpus_data['PreparedDataObtained']]\n",
    "#print('que hay en data', data)\n",
    "data_json_format = []\n",
    "#print(\"este es el formato de data\",data)\n",
    "#print(\"este es el elemento\", data)\n",
    "for elem in data:\n",
    "    #print(elem)\n",
    "    #elem = elem.to_json() esto lo borre\n",
    "    elem = js.dumps(elem, cls=NumPyEncoder)\n",
    "    data_json_format.append(elem)\n",
    "\n",
    "new_dict['PreparedDataObtained_fromPython'] = js.loads(data_json_format[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dict_key in new_dict['PreparedDataObtained_fromPython']['tinfo'].keys():\n",
    "    current_list = new_dict['PreparedDataObtained_fromPython']['tinfo'][dict_key]\n",
    "    my_list = ['new item' if i=='old item' else i for i in my_list]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dict['PreparedDataObtained_fromPython']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stringtest = js.dumps(new_dict['PreparedDataObtained_fromPython']['tinfo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "js.loads(stringtest).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dict['PreparedDataObtained_fromPython']['mdsDat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dict['PreparedDataObtained_fromPython']['tinfo'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topicvisexplorer.single_corpus_data['relevantDocumentsDict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing guided LDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_eta(priors, etadict, ntopics):\n",
    "    print('Creando eta')\n",
    "    eta = np.full(shape=(ntopics, len(etadict)), fill_value=1) # create a (ntopics, nterms) matrix and fill with 1\n",
    "    for topic, list_words in priors.items():\n",
    "        for word in list_words:\n",
    "            keyindex = [index for index,term in etadict.items() if term==word] # look up the word in the dictionary id2word\n",
    "            print('esto es mmm', keyindex, word, topic)\n",
    "            if (len(keyindex)>0): # if it's in the dictionary\n",
    "                    eta[topic,keyindex[0]] = 1e7  # put a large number in there\n",
    "    eta = np.divide(eta, eta.sum(axis=0)) # normalize so that the probabilities sum to 1 over all topics\n",
    "    return eta\n",
    "\n",
    "import gensim\n",
    "from _guidedLda_helpers import *\n",
    "\n",
    "topicvisexplorer.single_corpus_data['lda_model']\n",
    "\n",
    "\n",
    "print('estoy en la funcion para hacer el splitting')\n",
    "\n",
    "#1.= Get old seeds from the topics that it shouldnt change\n",
    "lda_model = topicvisexplorer.single_corpus_data['lda_model']\n",
    "id2word = topicvisexplorer.single_corpus_data['id2word']\n",
    "corpus = topicvisexplorer.single_corpus_data['corpus']\n",
    "\n",
    "\n",
    "last_lda_model_dict_all_terms = dict()\n",
    "for topic_id in range(lda_model.num_topics):\n",
    "    current_list = [id2word[w]for w,p in lda_model.get_topic_terms(topic_id, topn=20)]\n",
    "    last_lda_model_dict_all_terms[topic_id] = current_list\n",
    "print('Estas son las semillas actualeees', last_lda_model_dict_all_terms)\n",
    "#2 Add new seeds\n",
    "\n",
    "\n",
    "#3 Create eta\n",
    "eta = create_eta(last_lda_model_dict_all_terms, id2word, ntopics = 11)\n",
    "new_guided_lda_model = create_new_guided_lda_model(eta, id2word, corpus, 11)\n",
    "print('esto fue lo q se genero', new_guided_lda_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = new_guided_lda_model\n",
    "\n",
    "matrix_documents_topic_contribution, _ = lda_model.inference(corpus)\n",
    "matrix_documents_topic_contribution /= matrix_documents_topic_contribution.sum(axis=1)[:, None]\n",
    "matrix_documents_topic_contribution = pd.DataFrame(matrix_documents_topic_contribution)\n",
    "\n",
    "df = pd.DataFrame(topicvisexplorer.single_corpus_data['relevantDocumentsDict'])\n",
    "contents = df[df.columns[-1]].reset_index(drop=True)\n",
    "matrix_documents_topic_contribution = pd.concat([matrix_documents_topic_contribution, contents], axis=1)\n",
    "print('Esta es la matriz final resultante', matrix_documents_topic_contribution.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame(topicvisexplorer.single_corpus_data['relevantDocumentsDict'])\n",
    "contents = df[df.columns[-1]].reset_index(drop=True)\n",
    "matrix_documents_topic_contribution = pd.concat([matrix_documents_topic_contribution, contents], axis=1)\n",
    "print('Esta es la matriz final resultante', matrix_documents_topic_contribution.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_documents_topic_contribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_guided_lda_model.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#topicvisexplorer.single_corpus_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#vis.load_single_corpus_data(\"models_output/single_corpus_northamerica_cambridge_analytica_lda_mallet_gensim_new_prepared_data_enero_11.pkl\")\n",
    "#vis.load_multi_corpora_data(\"models_output/multi_corpora_data_europe_northamerica_ca_lda_mallet_gensim_new_prepared_data_enero_11.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test topic splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_term_dists = topicvisexplorer.single_corpus_data['data_dict']['topic_term_dists']\n",
    "doc_topic_dists = topicvisexplorer.single_corpus_data['data_dict']['doc_topic_dists']\n",
    "vocab = topicvisexplorer.single_corpus_data['data_dict']['vocab']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(topic_term_dists[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(topic_term_dists[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(doc_topic_dists[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topicvisexplorer.single_corpus_data['data_dict'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topicvisexplorer.single_corpus_data['data_dict']['term_frequency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(topic_term_dists.shape)\n",
    "print(doc_topic_dists.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topicvisexplorer.single_corpus_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load lda model\n",
    "lda_model = topicvisexplorer.single_corpus_data[\"lda_model\"]\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "common_dictionary = Dictionary(common_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_texts = [\n",
    "    ['computer', 'time', 'graph'],\n",
    "    ['survey', 'response', 'eps'],\n",
    "    ['human', 'system', 'computer']\n",
    "]\n",
    "other_corpus = [common_dictionary.doc2bow(text) for text in other_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = topicvisexplorer.single_corpus_data['corpus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new corpus, made of previously unseen documents.\n",
    "\n",
    "\n",
    "unseen_doc = corpus[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = lda_model[unseen_doc]  # get topic probability distribution for a document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "que hace bow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = np.ones([9, 5, 7, 4])\n",
    "#c = np.ones([9, 5, 4, 3])\n",
    "#np.dot(a, c).shape\n",
    "#(9, 5, 7, 9, 5, 3)\n",
    "#np.matmul(a, c).shape\n",
    "#(9, 5, 7, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.matmul(topic_term_dists, doc_topic_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_topic_dists[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_term_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
